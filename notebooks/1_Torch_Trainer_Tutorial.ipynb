{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b13ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a290f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be run only once for running session\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e29f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_trainer import (\n",
    "    EarlyStopping, ModelCheckpoint,\n",
    "    History, Profiler,\n",
    "    Trainer \n",
    ")\n",
    "from utils.losses import FocalLoss\n",
    "from utils.metrics import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c7467",
   "metadata": {},
   "source": [
    "#### Note: <br>\n",
    "• **utils.losses** contains custom loss definitions <br>\n",
    "• **utils.metrics** contains custom metric definitions <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074503b",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95512c5",
   "metadata": {},
   "source": [
    "# 1) Model Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322c00",
   "metadata": {},
   "source": [
    "#### Note: <br>\n",
    "• It is good to perform profiling of the model before training so that we will get to know the model complexity. <br>\n",
    "• If performing the profiling for device \"cuda\", it is suggested to set **\"gpu_warmup\"** to **True** for accurate time measurements. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v3_small()\n",
    "sample_inputs = torch.randn((2, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = Profiler()\n",
    "results = profiler(\n",
    "    model=model, \n",
    "    inputs=sample_inputs,      # Single input = A torch.tensor(); Multiple inputs = A list of torch.tensor()'s\n",
    "    devices=[\"cpu\", \"cuda\"],   # A list of target device(s) e.g [\"cpu\"], [\"cuda\"], [\"cpu\", \"cuda\"]\n",
    "    n_iters=10,                # Number of iterations to be performed\n",
    "    gpu_warmup=True            # Must be set to True if devices=[\"cuda\"] for warming up the gpu before profiling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the results as pandas dataframe\n",
    "results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the results as dictionary\n",
    "results.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2624c9",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd196f8",
   "metadata": {},
   "source": [
    "# 2) Model Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e74b7",
   "metadata": {},
   "source": [
    "#### Note: <br>\n",
    "• Trainer requires the dataloader and the model to follow some I/O structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96975d",
   "metadata": {},
   "source": [
    "### 2.1) Single Input - Single Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1,51)]\n",
    "y = [2 * i for i in range(1, 51)]\n",
    "\n",
    "# 2.1.a) Dataloader\n",
    "class DatasetPreprocessor(Dataset):\n",
    "    \"\"\" \n",
    "    A Single Input - Single Output Dataset \n",
    "    Should return a sequence of (input, target)\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs: list, targets: list):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # input\n",
    "        x = self.inputs[index]\n",
    "\n",
    "        # target\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return (\n",
    "            np.array([x], dtype=np.float32),\n",
    "            np.array([y], dtype=np.float32)\n",
    "        )\n",
    "\n",
    "dataset = DatasetPreprocessor(x, y)\n",
    "dataloader = DataLoader(\n",
    "                        dataset=dataset, \n",
    "                        batch_size=10,\n",
    "                        shuffle=True, \n",
    "                        num_workers=0,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "\n",
    "# 2.1.b) Model\n",
    "class SISO(nn.Module):\n",
    "    \"\"\" \n",
    "    A Single Input - Single Output Model \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = example_conv_layer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out\n",
    "\n",
    "model = SISO()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 2.1.c) Instantiate Trainer\n",
    "trainer = Trainer(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1025ef",
   "metadata": {},
   "source": [
    "### 2.2) Single Input - Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1,51)]\n",
    "y1 = [2 * i for i in range(1, 51)]\n",
    "y2 = [3 * i for i in range(1, 51)]\n",
    "y3 = [4* i for i in range(1, 51)]\n",
    "\n",
    "# 2.2.a) Dataloader\n",
    "class DatasetPreprocessor(Dataset):\n",
    "    \"\"\" \n",
    "    A Single Input - Multiple Outputs Dataset.\n",
    "    Should return a sequence of (input, target_1, ... target_N)\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs: list, targets1: list, targets2: list, targets3: list):\n",
    "        self.inputs = inputs\n",
    "        self.targets1 = targets1\n",
    "        self.targets2 = targets2\n",
    "        self.targets3 = targets3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # input\n",
    "        x = self.inputs[index]\n",
    "\n",
    "        # targets\n",
    "        y1 = self.targets1[index]\n",
    "        y2 = self.targets2[index]\n",
    "        y3 = self.targets3[index]\n",
    "\n",
    "        return (\n",
    "            np.array([x], dtype=np.float32),\n",
    "            np.array([y1], dtype=np.float32),\n",
    "            np.array([y2], dtype=np.float32),\n",
    "            np.array([y3], dtype=np.float32)\n",
    "        )\n",
    "\n",
    "dataset = DatasetPreprocessor(x, y1, y2, y3)\n",
    "dataloader = DataLoader(\n",
    "                        dataset=dataset, \n",
    "                        batch_size=10,\n",
    "                        shuffle=True, \n",
    "                        num_workers=0,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "\n",
    "# 2.2.b) Model\n",
    "class SIMO(nn.Module):\n",
    "    \"\"\" \n",
    "    A Single Input - Multiple Outputs Model\n",
    "    Should return a sequence of (outpu_1, ... output_N) \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = example_conv_layer1()\n",
    "        self.layer2 = example_conv_layer2()\n",
    "        self.layer3 = example_conv_layer3()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(x)\n",
    "        out3 = self.layer3(x)\n",
    "        return out1, out2, out3\n",
    "    \n",
    "model = SIMO()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 2.2.c) Instantiate Trainer\n",
    "trainer = Trainer(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6326fe8",
   "metadata": {},
   "source": [
    "### 2.3) Multiple Inputs - Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [i for i in range(1,51)]\n",
    "x2 = [i for i in range(1,51)]\n",
    "y1 = [2 * i for i in range(1, 51)]\n",
    "y2 = [3 * i for i in range(1, 51)]\n",
    "y3 = [4 * i for i in range(1, 51)]\n",
    "\n",
    "# 2.3.a) Dataloader\n",
    "class DatasetPreprocessor(Dataset):\n",
    "    \"\"\" \n",
    "    A Single Input - Multiple Outputs Dataset \n",
    "    Should return a sequence of (input_1, ... input_N, target_1, ... target_N)\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs1: list, inputs2: list, targets1: list, targets2: list, targets3: list):\n",
    "        self.inputs1 = inputs1\n",
    "        self.inputs2 = inputs2\n",
    "        self.targets1 = targets1\n",
    "        self.targets2 = targets2\n",
    "        self.targets3 = targets3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs1)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # inputs\n",
    "        x1 = self.inputs1[index]\n",
    "        x2 = self.inputs2[index]\n",
    "\n",
    "        # targets\n",
    "        y1 = self.targets1[index]\n",
    "        y2 = self.targets2[index]\n",
    "        y3 = self.targets3[index]\n",
    "\n",
    "        return (\n",
    "            np.array([x1], dtype=np.float32),\n",
    "            np.array([x2], dtype=np.float32),\n",
    "            np.array([y1], dtype=np.float32),\n",
    "            np.array([y2], dtype=np.float32),\n",
    "            np.array([y3], dtype=np.float32)\n",
    "        )\n",
    "\n",
    "dataset = DatasetPreprocessor(x1, x2, y1, y2, y3)\n",
    "dataloader = DataLoader(\n",
    "                        dataset=dataset, \n",
    "                        batch_size=10,\n",
    "                        shuffle=True, \n",
    "                        num_workers=0,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "\n",
    "# 2.3.b) Model\n",
    "class MIMO(nn.Module):\n",
    "    \"\"\" \n",
    "    A Multiple Inputs - Multiple Outputs Model \n",
    "    Should return a sequence of (outpu_1, ... output_N)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = example_conv_layer1()\n",
    "        self.layer2 = example_conv_layer2()\n",
    "        self.layer3 = example_conv_layer3()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.layer1(x1)\n",
    "        out2 = self.layer2(x2)\n",
    "        out3 = self.layer3(x2)\n",
    "        return out1, out2, out3\n",
    "    \n",
    "model = MIMO()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 2.3.c) Instantiate Trainer\n",
    "trainer = Trainer(model, num_inputs=2, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0977d39",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d02ac",
   "metadata": {},
   "source": [
    "## Consider, we have the following things in place:\n",
    "\n",
    "1) model  -> A model object of parent type **torch.nn**  e.g. torch.nn.Conv2d <br>\n",
    "2) train_dataloader -> A dataloader object of type **torch.utils.data.DataLoader** <br>\n",
    "3) [Optional] val_dataloader -> A dataloader object of type **torch.utils.data.DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76d57d",
   "metadata": {},
   "source": [
    "### The most basic usage of the Trainer would look as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "device = torch.device(\"cuda\")\n",
    "criterion = FocalLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "\n",
    "# Instantiate Trainer\n",
    "trainer = Trainer(model, device=device)\n",
    "\n",
    "# Compile Trainer\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,    \n",
    ")\n",
    "\n",
    "# Fit Trainer\n",
    "history = trainer.fit(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=train_dataloader\n",
    ")\n",
    "\n",
    "# OR if we have validation dataloader,\n",
    "# then;\n",
    "history = trainer.fit(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloder\n",
    ")\n",
    "\n",
    "# + Logging epoch results\n",
    "history = trainer.fit(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloder,\n",
    "    verbose=True,                   # Default value = False. Enables logging for epoch results (epoch_num, loss, lr, metrics(s))\n",
    "    verbose_epochs_frequency=10     # Default value = 1. Frequency of epochs for logging. e.g. if set to 10, will log for every 10 epochs\n",
    "    verbose_steps_frequency=50     # Default value = 0. Frequency of steps for logging (only for verbosed epochs).\n",
    ")                                   # e.g. if set to 50, will log for every 50 steps (only for verbosed epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4965488",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4242c80",
   "metadata": {},
   "source": [
    "# 3) + Learning Rate Scheduler: OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=1e-4,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=10,  # len(train_dataloader)\n",
    "    div_factor=3,\n",
    "    pct_start=0.3,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Compile Trainer\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc4018",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985e9c0",
   "metadata": {},
   "source": [
    "# 4) + Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "metric_accuracy = MulticlassAccuracy(num_classes=10, device=device)\n",
    "metric_precision = MulticlassPrecision(num_classes=10, device=device)\n",
    "metric_recall = MulticlassRecall(num_classes=10, device=device)\n",
    "metric_f1_score = MulticlassF1Score(num_classes=10, device=device)\n",
    "\n",
    "# Compile Trainer\n",
    "## Single metric\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy\n",
    "    }\n",
    ")\n",
    "\n",
    "## Multiple metrics\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf0f5a",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600077b3",
   "metadata": {},
   "source": [
    "# 5) + Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39987968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpointing\n",
    "checkpoint = ModelCheckpoint(\n",
    "    root_dir=\"experiments\",\n",
    "    name=\"my_model\",\n",
    "    save_best_only=True,     # saves only the best model; if set to False, saves model for every epoch\n",
    "    save_model_only=True     # saves only the model; if set to False, saves model + optimizer + scheduler if provided\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "# Compile Trainer\n",
    "## Only Model checkpointing\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "## Only Early stopping\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "## Both - Order does not matter\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f31425",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90439103",
   "metadata": {},
   "source": [
    "# 6) + Training Precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Trainer\n",
    "## FP32 (If not specified, default Precision is FP32; Can be explicitly defined as well)\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    precision=\"32\"    # Default value = \"32\"\n",
    ")\n",
    "\n",
    "## FP16 AMP (Automatic Mixed Precision)\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    precision=\"16-mixed\"\n",
    ")\n",
    "\n",
    "## BFP16 AMP (Automatic Mixed Precision)\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    precision=\"bf16-mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99458372",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b616cbc",
   "metadata": {},
   "source": [
    "# 7) + Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_acc_steps = 8\n",
    "if len(train_dataloader) % gradient_acc_steps == 0:\n",
    "    scheduler_steps_per_epoch = int(len(train_dataloader) / gradient_acc_steps)\n",
    "else:\n",
    "    scheduler_steps_per_epoch = int(len(train_dataloader) / gradient_acc_steps) + 1\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=1e-4,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=scheduler_steps_per_epoch,  # num gradient accumulation steps per epoch\n",
    "    div_factor=3,\n",
    "    pct_start=0.3,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Compile Trainer\n",
    "trainer.compile(\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        \"accuracy\" : metric_accuracy,\n",
    "        \"precision\" : metric_precision,\n",
    "        \"recall\" : metric_recall,\n",
    "        \"f1_score\" : metric_f1_score\n",
    "    },\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    precision=\"32\",\n",
    "    gradient_acc=True,       # enables training with accumulation of gradients\n",
    "    gradient_acc_steps=gradient_acc_steps     # the number of steps/ iterations that the gradients to be accumulated\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d34a8",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4327f2",
   "metadata": {},
   "source": [
    "# 8) History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd89396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Trainer\n",
    "history = trainer.fit(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloder\n",
    ")\n",
    "\n",
    "# see keys\n",
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942dda22",
   "metadata": {},
   "source": [
    "### 8.1) Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f798d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot both losses (train and val)\n",
    "history.plot_loss()\n",
    "### + save to file\n",
    "history.plot_loss(save_path=\"/path/to/file.png\")\n",
    "\n",
    "## Plot only train loss\n",
    "history.plot_loss(_type=\"train\")\n",
    "### + save to file\n",
    "history.plot_loss(_type=\"train\", save_path=\"/path/to/file.png\")\n",
    "\n",
    "## Plot only val loss\n",
    "history.plot_loss(_type=\"val\")\n",
    "### + save to file\n",
    "history.plot_loss(_type=\"val\", save_path=\"/path/to/file.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef13fcf",
   "metadata": {},
   "source": [
    "### 8.2) Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot all metrics (e.g accuracy, precision, recall, f1_score) - train and val\n",
    "history.plot_metrics()\n",
    "\n",
    "### + only plot train metrics\n",
    "history.plot_metrics(_type=\"train\")\n",
    "### + save to file\n",
    "history.plot_metrics(_type=\"train\", save_path=\"/path/to/file.png\")\n",
    "\n",
    "### + only plot val metrics\n",
    "history.plot_metrics(_type=\"val\")\n",
    "### + save to file\n",
    "history.plot_metrics(_type=\"val\", save_path=\"/path/to/file.png\")\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "## Plot specific metric (e.g only accuracy)\n",
    "history.plot_metric(name=\"accuracy\")\n",
    "\n",
    "### + only plot train metric\n",
    "history.plot_metric(name=\"accuracy\", _type=\"train\")\n",
    "### + save to file\n",
    "history.plot_metric(name=\"accuracy\", _type=\"train\", save_path=\"/path/to/file.png\")\n",
    "\n",
    "### + only plot val metric\n",
    "history.plot_metric(name=\"accuracy\", _type=\"val\")\n",
    "### + save to file\n",
    "history.plot_metric(name=\"accuracy\", _type=\"val\", save_path=\"/path/to/file.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1bbd7",
   "metadata": {},
   "source": [
    "### 8.3) View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98821ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as dictionary\n",
    "hist_dict = history.to_dict()\n",
    "\n",
    "# as pandas\n",
    "hist_df = history.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d74ae",
   "metadata": {},
   "source": [
    "### 8.4) Save History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ab249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history (dict) to pickle file\n",
    "history.save_history(save_path=\"/path/to/file.pkl\")\n",
    "\n",
    "# Save as csv file\n",
    "history.to_csv(save_path=\"/path/to/file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395be73e",
   "metadata": {},
   "source": [
    "### 8.5) Load History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3741cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "\n",
    "# Load history (dict) from pickle file\n",
    "history.load_history(load_path=\"/load/from/file.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83108956",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf28a82",
   "metadata": {},
   "source": [
    "# 9) Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Trainer\n",
    "history = trainer.fit(\n",
    "    num_epochs=100,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloder,\n",
    "    progress_bar=True        # Default value = False. Displays the progress bar for every epoch\n",
    ")                            # with (epoch_num, loss, lr, metrics(s)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb709bd",
   "metadata": {},
   "source": [
    "#### Note: <br>\n",
    "• Only **torch.optim.lr_scheduler.OneCycleLR** scheduler is supported by the Trainer as this scheduler is popular and widely used. It is based on a 2018 paper titled \"Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates\" (https://arxiv.org/abs/1708.07120) <br>\n",
    "\n",
    "• Loss & Metrics must return an average value or reduction by 'mean'. The Loss function and Metric(s) functions(s) should accept arguments (preds, targets). If a model produces multiple outputs (output_1, output_2, ..., output_N), the respective metric function should access its desired output using index. e.g. preds[0] & target[0]. <br>  \n",
    "\n",
    "• In checkpoint callbacks, it is suggested to set **\"save_best_only\"** to **True**, otherwise the Trainer will unnecessarily save the checkpoints for all epochs which results in increasing disk usage. <br>\n",
    "\n",
    "• In checkpoint callbacks, if **\"save_model_only\"** is set to **True** then the Trainer will only save the model as checkpoint. If set to **False**, the Trainer will save the model, optimizer, scheduler as checkpoint. Trainer will create a checkpoint directory: **<root_dir>/<name>/runs_0/** and will save the checkpoints at this location. <br>\n",
    "\n",
    "• Early Stopping will stop the training if the model is overfitting. It has a \"patience\" parameter that defines for how many upcoming epochs the training should continue (if validation loss is not improved since last epoch) before terminating the training. It only works if validation dataloader is passed to trainer.fit() method. <br>\n",
    "\n",
    "• Gradient Accumulation should be used when you are facing OOM errors. Possible reasons: the model is huge (in terms of size, flops, and number of parameters) or large batch size is used for training. It helps in solving this OOM error, by let us train with less number of batch size, but updating the gradients for the desired batch size i.e. `gradient_acc_steps`.\n",
    "\n",
    "• For \"trainer.fit()\" method, **progress_bar** and **verbose** both can be set to `False` or any one of them can be set to `False` and other to `True`. But if both are set to `True`, **progress_bar** will be selected and **verbose** will be disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ebb182",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
